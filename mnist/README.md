# Final Exam

- On each round for same split accuracy changes as every time we get same amount of random suffeled data.
- A depth for Decision tree classifier increases train accuracy becomes 1 whereas test and validation accuracy were at 85.
- This is beacuse model overfits as depth increases it overfits on training data.
- Also decision tree classifier are more vulnerable to overfitting.
- When depth is low accuracy is low as depth is increases accuracy increases but at higher depth mode overfits.

# Output1
![alt text](https://github.com/anurag-saraswat/MNIST_Example/blob/feature/final_exam/mnist/result.png)

# Output2
![alt text](https://github.com/anurag-saraswat/MNIST_Example/blob/feature/final_exam/mnist/result2.png)
