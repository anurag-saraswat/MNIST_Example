# Final Exam

- On each round for same split accuracy changes as every time we get same amount of random suffeled data.
- A depth for Decision tree classifier increases train accuracy becomes 1 whereas test and validation accuracy were at 85.
- This is beacuse model overfits as depth increases it overfits on training data.
- Also decision tree classifier are more vulnerable to overfitting.
- When depth is low accuracy is low as depth is increases accuracy increases but at higher depth mode overfits.

Depth    Run1                      Run2                      Run3                      Average
-------  ------------------------  ------------------------  ------------------------  ------------------------
         ['train', 'val', 'test']  ['train', 'val', 'test']  ['train', 'val', 'test']  ['train', 'val', 'test']
1        [0.21, 0.21, 0.2]         [0.19, 0.2, 0.16]         [0.17, 0.16, 0.2]         [0.2, 0.18, 0.18]
2        [0.33, 0.32, 0.33]        [0.29, 0.31, 0.27]        [0.29, 0.29, 0.32]        [0.32, 0.29, 0.3]
3        [0.48, 0.49, 0.49]        [0.44, 0.49, 0.39]        [0.44, 0.39, 0.46]        [0.49, 0.44, 0.43]
4        [0.59, 0.6, 0.69]         [0.55, 0.6, 0.58]         [0.53, 0.44, 0.64]        [0.64, 0.59, 0.54]
5        [0.69, 0.75, 0.78]        [0.65, 0.7, 0.67]         [0.66, 0.63, 0.72]        [0.76, 0.68, 0.68]
6        [0.81, 0.82, 0.88]        [0.75, 0.74, 0.77]        [0.77, 0.67, 0.79]        [0.85, 0.76, 0.73]
7        [0.88, 0.9, 0.92]         [0.81, 0.8, 0.82]         [0.84, 0.76, 0.79]        [0.91, 0.81, 0.78]
8        [0.92, 0.94, 0.95]        [0.83, 0.82, 0.84]        [0.81, 0.79, 0.81]        [0.94, 0.83, 0.8]
9        [0.95, 0.96, 0.97]        [0.87, 0.83, 0.85]        [0.85, 0.79, 0.82]        [0.96, 0.84, 0.8]
10       [0.98, 0.98, 0.99]        [0.88, 0.81, 0.87]        [0.86, 0.79, 0.84]        [0.98, 0.84, 0.82]
11       [0.99, 0.99, 1.0]         [0.86, 0.84, 0.86]        [0.86, 0.82, 0.84]        [1.0, 0.85, 0.83]
12       [1.0, 1.0, 1.0]           [0.86, 0.82, 0.83]        [0.87, 0.81, 0.84]        [1.0, 0.82, 0.82]
13       [1.0, 1.0, 1.0]           [0.86, 0.84, 0.85]        [0.86, 0.82, 0.85]        [1.0, 0.84, 0.84]
14       [1.0, 1.0, 1.0]           [0.87, 0.84, 0.88]        [0.86, 0.81, 0.85]        [1.0, 0.86, 0.83]
15       [1.0, 1.0, 1.0]           [0.85, 0.85, 0.89]        [0.87, 0.81, 0.86]        [1.0, 0.87, 0.84]
16       [1.0, 1.0, 1.0]           [0.86, 0.83, 0.87]        [0.86, 0.8, 0.84]         [1.0, 0.85, 0.82]
17       [1.0, 1.0, 1.0]           [0.88, 0.84, 0.87]        [0.87, 0.8, 0.86]         [1.0, 0.86, 0.83]
18       [1.0, 1.0, 1.0]           [0.87, 0.84, 0.86]        [0.86, 0.81, 0.84]        [1.0, 0.85, 0.82]
19       [1.0, 1.0, 1.0]           [0.84, 0.82, 0.87]        [0.87, 0.81, 0.86]        [1.0, 0.84, 0.84]
20       [1.0, 1.0, 1.0]           [0.87, 0.86, 0.87]        [0.86, 0.8, 0.84]         [1.0, 0.86, 0.82]
